{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "06dc74a6-625e-4f8b-90d3-a7e6deb862e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1709996f-69d1-41a1-9af1-e8b0eb59c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8f708c7a-4dca-4759-8584-9dc5145e8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7e046d9c-d238-4f4b-a224-96d0040f8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/corpora/stopwords/english', 'r') as file:\n",
    "    sw = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ecb32a16-2176-4fe3-9a5f-961157fbef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.read_csv('../static/model/vocabulary.txt', header = None)\n",
    "token = vocab[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d5f9bce5-1c49-42bc-b9db-08ac68c85dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "89f14007-fe9d-468f-acfe-a6b08ef10d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    data = pd.DataFrame([text], columns = ['tweet'])\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', x, flags = re.MULTILINE) for x in x.split()))\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(remove_punctuations)\n",
    "    data[\"tweet\"] = data[\"tweet\"].str.replace(r'\\d+','', regex = True)\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join(ps.stem (x) for x in x.split()))\n",
    "    return data[\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ff8cf691-fb6a-4f59-a484-af9d47ef3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(ds, vocabulary):\n",
    "    vectorized_lst = []\n",
    "\n",
    "    for sentence in ds:\n",
    "        sentence_lst = np.zeros(len(vocabulary))\n",
    "    \n",
    "        for i in range(len(vocabulary)):\n",
    "            if vocabulary[i] in sentence.split():\n",
    "                sentence_lst[i] = 1\n",
    "    \n",
    "        vectorized_lst.append(sentence_lst)\n",
    "    \n",
    "    vectorized_lst_new = np.asarray(vectorized_lst, dtype=np.float32)\n",
    "    \n",
    "    return vectorized_lst_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fd3f9824-b9e8-4f10-aa88-c5febfa817d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(vectorized_text):\n",
    "    prediction = model.predict(vectorized_text)\n",
    "    if prediction == 1:\n",
    "        return 'negative review'\n",
    "    else:\n",
    "        return 'positive review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7fc8ce81-1dcb-4a98-ad71-c2ba5f1e46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = 'Love this product and recomended!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8e6b08b7-5e3c-4ed0-bf79-26325a459f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_text = preprocessing(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eec1fb0b-b61c-4c1f-b977-d0d8768b014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(preprocessed_text, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "454a7284-9289-408a-9ba7-895ddb167fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predition = get_prediction(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1c214745-37a4-42d7-a49b-bcd73d7d16a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive review'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
